
> [!CITE] Definition 1 (agent)
> Let ğ’œ be a set of actions. Let ğ›• be a set of observations. An agent "A" can be given via a **policy function** ğœ‹ : Î˜ â†’ ğ’œ. Given a time series of observations âŸ¨ğ‘œâ‚œâŸ©â‚œâˆˆâ„¤ for some **time space** â„¤, the agent can thus generate a time series of actions âŸ¨ğ‘â‚œâŸ©â‚œâˆˆâ„¤ by applying ğ‘â‚œ = ğœ‹(ğ‘œâ‚œ).

## ELI5

An **agent** operates by perceiving its environment and performing actions based on those perceptions. This definition introduces the relationship between the **observation space** (Î˜ or O), the **action space** (ğ’œ or A), and a **policy function** (ğœ‹) that governs the agent's behavior.

---

### Components of the Definition

1. **Action Space (ğ’œ):**  
    The set of all possible actions that the agent can perform. For example, in a cleaning robot scenario, the action space could include `{vacuum, move_to_room_A, move_to_room_B, do_nothing}`.
    
2. **Observation Space (ğ›• or O):**  
    The set of all possible observations the agent can make about its environment. An observation provides the agent with information about the current state of the world, such as whether a room is clean or dirty, or which room the agent is currently in.
    
3. **Policy Function (ğœ‹):**  
    A function that maps observations (ğ‘œâ‚œ âˆˆ O) to actions (ğ‘â‚œ âˆˆ A). The policy function defines how the agent chooses an action based on its current observation. Formally, this is expressed as:  
    ğœ‹: ğ›• â†’ ğ’œ.
    
4. **Time Space (â„¤):**  
    Observations and actions occur sequentially over time. The time space â„¤ represents this sequence, allowing the agent to process a time series of observations âŸ¨ğ‘œâ‚œâŸ©â‚œâˆˆâ„¤ and generate a corresponding time series of actions âŸ¨ğ‘â‚œâŸ©â‚œâˆˆâ„¤.
    

---

### Explanation of the Policy Function

The policy function (ğœ‹) is central to the agent's operation. It takes an observation as input and determines the appropriate action to take. For example:

- Observation: `(current_room = A, is_dirty = True)`
- Action: `vacuum`.

![[Pasted image 20241205155501.png]]
"One Observation leads to an action based on the policy that was given"

This function encapsulates the agent's decision-making process, allowing it to interact with its environment in a structured and consistent manner.

---

### Summary
An agent uses observations from its environment to determine actions through a policy function. Over time, the agent continuously observes the environment and acts accordingly, forming a sequence of observations and actions. This framework enables the systematic design of intelligent agents that can operate in dynamic environments.