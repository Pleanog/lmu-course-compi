Good Read:
[[Artificial Intelligence - A Modern Approach (3rd Edition).pdf]]
Russell, Norvig. Artificial Intelligence: A Modern Approach 1995, 2003, 2009, 2020

![[Pasted image 20241205155649.png]]

This image illustrates the interaction between an **agent** (e.g., a vacuum cleaner robot) and its **environment**.


### Key Components:

1. **Agent**: The system taking actions (e.g., the vacuum robot).
    - **Sensors**: Gather observations from the environment (e.g., detect dirt or walls).
    - **Behavior**: Decides the next action based on the observations (e.g., move or clean dirt).
    - **Actuators**: Execute actions in the environment (e.g., vacuum dirt or move forward).
2. **Environment**:
	- The space where the agent operates (e.g., a room the robot is in, dirt).
4. **Cycle**:
    - The agent's **sensors** observe the environment.
    - Based on these **observations**, the agent's **behavior** determines actions.
    - **Actions** affect the environment, creating a feedback loop.

#  Observation and Action Spaces

## Example (1): Vacuum World
![[Pasted image 20241205154030.png]]
### Environment
- Two rooms: **Room A** and **Room B**.
- Each room can be either **dirty** (1) or **clean** (0).
### Sensors
- Detect:
  1. The current room the agent (robot) is in.
  2. Whether the current room is dirty.

### Observation Space ($\mathcal{O}$ )
The observation space defines all possible states the agent can observe.
#### Structure
This is what an observation looks like:
`O = (current_room, is_current_room_dirty)`
#### Possible Observations
The agent can observe combinations of the current room (**A** or **B**) and whether it is dirty (**1** for dirty, **0** for clean):

```
observation space O = {O‚ÇÅ, O‚ÇÇ, ...} = { (A, 1), (A, 0), (B, 1), (B, 0) }
```
These are all possible observations the robot can have: 
- `(A, 1)` - Room A is dirty.
- `(A, 0)` - Room A is clean.
- `(B, 1)` - Room B is dirty.
- `(B, 0)` - Room B is clean.

**Example**: If the robot is in **Room A**, and it is dirty, the observation is `(A, 1)`.

---

### Action Space (ùíú)
The action space defines all possible actions the agent can take.

```
action space ùíú = {a‚ÇÅ, a‚ÇÇ, ...} = {vacuum, change_room}
```

#### Structure
The actions are:
- a‚ÇÅ = `vacuum` - Clean the current room.
- a‚ÇÇ = `change_room` - Move to the other room.

**Example**: If the robot is in **Room A** and it is dirty, it can:
- Take action `vacuum` to clean Room A.
- Take action `change_room` to move to Room B.

---

### Behavior
- **If the current room is dirty**, the agent vacuums.
- **If the current room is clean**, the agent moves to the next room.

#### Example Behavior
1. Start in Room A (`(A, 1)`).
   - Observation: Room A is dirty.
   - Action: Vacuum.
2. Transition to Room A clean (`(A, 0)`).
   - Observation: Room A is clean.
   - Action: Change room.
3. Move to Room B (`(B, 1)`).
   - Observation: Room B is dirty.
   - Action: Vacuum.
4. End when all rooms are clean.

This cycle repeats until the environment is fully cleaned.

---

## Example (2): The Grid World 
![[Pasted image 20241205151804.png]]

```
observation space O = {O‚ÇÅ, O‚ÇÇ, ...} = {block, diamond, lava, start, agent, empty}
```

```
action space ùíú = {a‚ÇÅ, a‚ÇÇ, ...} = {go_north, go_west, go_east, go_south, do_nothing}
```

## Example (3): Stock Trading

![[Pasted image 20241205153933.png]]

In this example, the agent operates in the context of stock trading, where it observes various market indicators and takes actions such as buying, selling, or doing nothing.

---

### Observation Space ($\mathcal{O}$ )
The observation space in stock trading is more complex than simpler scenarios. It consists of tuples containing stock data and other relevant information like news and timestamps.

```
observation space O = {O‚ÇÅ, O‚ÇÇ, ...} = {
	< ('Meta', -3.2, t‚ÇÅ, t‚ÇÇ),
      ('SAP', +3.2, t‚ÇÉ, t‚ÇÑ),
      ('Google', +8.1, t‚ÇÖ, t‚ÇÜ),
      ... >
	< ('Breacking news', t‚Çá),
      ('Financial Crisis incoming', t‚Çà),
      ... >
}
```

Where each observation can contain:
1. **Stock Information**: Tuples of stock ticker symbols, percentage changes, and timestamps (`t‚ÇÅ`, `t‚ÇÇ`).
2. **News Information**: News headlines and timestamps `t‚Çà`.

### Formal Representation
```
O = ‚ü® S √ó ‚Ñù √ó T √ó T ‚ü© √ó ‚ü® S √ó T ‚ü©
```

Where:
- `S`: A string representing the stock ticker (e.g., "Meta", "SAP").
- `‚Ñù`: The percentage change in the stock value (real number).
- `T`: The timestamp when the observation took place.
- `√ó` (Cartesian product): Combines sets to form tuples of all possible combinations.

---

### Action Space (ùíú)
The action space defines all possible actions the agent can take, such as trading stocks or doing nothing.

```
ùíú = {a‚ÇÅ, a‚ÇÇ, ...} = { (buy, "SAP", 42), (sell, "Meta", 10), do_nothing }
```

### Formal Representation
```
ùíú = (buy, sell) √ó S √ó ‚Ñù ‚à™ {do_nothing}
```

Where:
- `(buy, sell)`: Actions for buying or selling.
- `S`: The stock ticker (e.g., "SAP").
- `‚Ñù`: The number of shares to trade (a real number).
- `do_nothing`: An action where the agent chooses not to act.

## Definition 1
[[Definition 1 (Agent)]]