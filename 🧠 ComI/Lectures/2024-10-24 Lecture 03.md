Goal Predicate "I know it is good when i see it!" $\gamma : (\mathcal{O}$ $\rightarrow$ ùíú ) $\rightarrow$ $\mathbb{B}  = \{0,1\}$

The goal predicate "I know it is good when I see it!" is an expression of how an agent determines whether something is good or not.

- $\gamma$:  This represents a function that maps from the observation space $\mathcal{O}$ to the action space $\mathcal{A}$, and ultimately outputs a boolean value ($\mathbb{B}$) which can be either 0 (not good) or 1 (good).
- $\mathcal{O}$ : The set of observations, representing what the agent can perceive from its environment.
- $\mathcal{A}$ : The set of actions the agent can take, based on the observations.
- $\mathbb{B}$  = \{0, 1\}: The result of the function is a binary value, indicating whether the observation-action pair is considered "good" (1) or "not good" (0).

In essence, this defines a decision-making process where the agent acts based on the observations and knows if the outcome is "good" when it occurs, without any explicit definition of what makes something "good" in advance.

---
## **The policy function: $\pi: \mathcal{O} \rightarrow \mathcal{A}$, **

The **policy function** denoted as $$\pi: \mathcal{O} \rightarrow \mathcal{A}$$maps an **observation** $\mathcal{o} \in \mathcal{O}$ (from the **observation space** $\mathcal{O}$) to an **action** $\mathcal{a} \in \mathcal{A}$ (from the **action space** $\mathcal{A}$).

**Explanation**:
The policy $\pi$ represents the decision-making rule for an agent. It determines which action the agent should take based on its current observation of the environment. This function serves as the agent's strategy for interacting with the environment.

**Example**:
In a **vacuum cleaner world**, where the vacuum can either `clean` or `move to another room`, the observation $\mathcal{o}$ might represent the state of the vacuum cleaner's current room (e.g., `dirty` or `clean`). The policy function $\pi(\mathcal{o})$ could then decide:
- If $\mathcal{o} =$ ``dirty``, the policy might output $\mathcal{a} =$ `vacuum`.
- If $\mathcal{o} =$ `clean`, the policy might output $\mathcal{a} =$ `move to another room`.
This means that the action depends directly on the current observation provided by the environment.
So the notation for a observaion might look like this: $\pi(\mathcal{o}) =$`vacuum`

## **The performance measure** or **value** of a **policy $(\pi)$: $\gamma(\pi)$**
$$
\gamma(\pi) \iff \neg \exists a \in \mathcal{A} : \forall o \in \mathcal{O} : \pi(o) = a
$$

This defines a condition for $\gamma$. It means that $\gamma$ holds if and only if (denoted by ‚ÄÖ‚Ää‚ü∫‚ÄÖ‚Ää/ iff) the agent does not perform the same action $a \in \mathcal{A}$  for all possible observations $\mathcal{o} \in \mathcal{O}$.

This means that the agent does not always perform the same action for every observation. If this condition $\gamma$ is true, the agent's policy is not static or trivial, meaning it adapts based on different observations.

---
![[Pasted image 20241209174203.png]]

$\mathcal{y}$ holds $\mathcal{iff}$ the agent never executes action "do_nothing" twice in a row.
$$
\mathcal{y}(\pi) \iff \neg \exists t: a_{t} = a_{t+1} = \text{"do nothing"}
$$
The formula is a **goal predicate** designed to enforce productive behavior in the agent.
##### Formula Breakdown:
- $\mathcal{y}(\pi)$: The goal predicate evaluates whether the agent's policy $\pi$ satisfies the condition.
- $\neg$ Logical **NOT**, meaning the condition must not hold.
- $\exists t$: "There exists a time $t$," indicating we are checking all points in time.
- $a_{t} = a_{t+1}$‚Äã: Actions at consecutive time steps $t$ and $t+1$.
- $a_{t} = a_{t+1}  = \text{"do nothing"}$: The agent performs **"do nothing"** at both $a_{t}$ and $a_{t+1}$.

By using logical quantifiers and conditions, the formula applies universally to all potential policies $\pi$, providing a generalizable rule.

---
## Process Notation


$$
\text{Behavior for Robot:}
\begin{cases} & \text{is\_clean(True).position("A").move("B").Robot,} \\
& \text{is\_clean(True).position("B").move("A").Robot,} \\
& \text{is\_clean(False).position("A").clean.Robot,} \\
& \text{is\_clean(False).position("B").clean.Robot} \\ \end{cases}
$$$$
\begin{align*}
\text{Robot = is\_clean}(True)\text{.(postion("A")
}.\overline{\mbox{move}}\langle\text{"B"}\rangle.Robot \enspace \enspace \enspace  \\ + \enspace \text{position("B")}\overline{\mbox{move}}\langle\text{"A"}\rangle.Robot) \\ + \enspace  \text{is\_clean}(False)\text{position(\_)}.\overline{\mbox{clean}}.Robot
\end{align*}

$$

- When the location is clean, it alternates between moving from `A` to `B` and vice versa.
- When the location is dirty, it focuses on cleaning the location before continuing its behavior.

[[Algorithm 1 (brute force (policy))]]

[[Algorithm 2 (random search(policy))]]
