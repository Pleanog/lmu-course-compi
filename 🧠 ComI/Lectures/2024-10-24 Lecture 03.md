Goal Predicate "I know it is good when i see it!" $\mathcal{y}$  : ($\mathcal{O}$ $\rightarrow$ ùíú ) $\rightarrow$ $\mathcal{B}$  = {0,1}

The goal predicate "I know it is good when I see it!" is an expression of how an agent determines whether something is good or not.

- $\mathcal{y}$:  This represents a function that maps from the observation space $\mathcal{O}$ to the action space $\mathcal{A}$, and ultimately outputs a boolean value (BBB) which can be either 0 (not good) or 1 (good).
- $\mathcal{O}$ : The set of observations, representing what the agent can perceive from its environment.
- $\mathcal{A}$ : The set of actions the agent can take, based on the observations.
- $\mathcal{B}$  = \{0, 1\}: The result of the function is a binary value, indicating whether the observation-action pair is considered "good" (1) or "not good" (0).

In essence, this defines a decision-making process where the agent acts based on the observations and knows if the outcome is "good" when it occurs, without any explicit definition of what makes something "good" in advance.

---

$$\pi(o) : \mathcal{O} \rightarrow \mathcal{A}$$

This represents a **policy function** $\pi(o)$ that maps an observation $\mathcal{o} \in \mathcal{O}$ (from the observation space) to an action $\mathcal{a} \in \mathcal{A}$ (in the action space). In simpler terms, the policy function determines the action that the agent should take based on its current specific observation right now.

**Example**: In the **vacuum world**, $\pi(o)$ would decide whether to clean or move to another room based on the current state (cleaning or not cleaning a room) it then could be for example: $\pi(o)$ = "vacuum"

**Definition of $\mathcal{y}(\pi)$**
$$
\mathcal{y}(\pi) \iff \neg \exists a \in \mathcal{A} : \forall o \in \mathcal{O} : \pi(o) = a
$$

This defines a condition for $\mathcal{y}$. It means that $\mathcal{y}$ holds if (denoted by ‚ÄÖ‚Ää‚ü∫‚ÄÖ‚Ää/ iff) the agent does not perform the same action $a \in \mathcal{A}$  for all possible observations $\mathcal{o} \in \mathcal{O}$.

This means that the agent does not always perform the same action for every observation. If this condition $\mathcal{y}$ is true, the agent's policy is not static or trivial, meaning it adapts based on different observations.

---
![[Pasted image 20241209174203.png]]

$\mathcal{y}$ holds $\mathcal{iff}$ the agent never executes action "do_nothing" twice in a row.
$$
\mathcal{y}(\pi) \iff \neg \exists t: a_{t} = a_{t+1} = \text{"do nothing"}
$$
The formula is a **goal predicate** designed to enforce productive behavior in the agent.
##### Formula Breakdown:
- $\mathcal{y}(\pi)$: The goal predicate evaluates whether the agent's policy $\pi$ satisfies the condition.
- $\neg$ Logical **NOT**, meaning the condition must not hold.
- $\exists t$: "There exists a time $t$," indicating we are checking all points in time.
- $a_{t} = a_{t+1}$‚Äã: Actions at consecutive time steps $t$ and $t+1$.
- $a_{t} = a_{t+1}  = \text{"do nothing"}$: The agent performs **"do nothing"** at both $a_{t}$ and $a_{t+1}$.

By using logical quantifiers and conditions, the formula applies universally to all potential policies $\pi$, providing a generalizable rule.

---
## Process Notation


$$
\text{Behavior for Robot:}
\begin{cases} & \text{is\_clean(True).position("A").move("B").Robot,} \\
& \text{is\_clean(True).position("B").move("A").Robot,} \\
& \text{is\_clean(False).position("A").clean.Robot,} \\
& \text{is\_clean(False).position("B").clean.Robot} \\ \end{cases}
$$$$
\begin{align*}
\text{Robot = is\_clean}(True)\text{.(postion("A")
}.\overline{\mbox{move}}\langle\text{"B"}\rangle.Robot \enspace \enspace \enspace  \\ + \enspace \text{position("B")}\overline{\mbox{move}}\langle\text{"A"}\rangle.Robot) \\ + \enspace  \text{is\_clean}(False)\text{position(\_)}.\overline{\mbox{clean}}.Robot
\end{align*}

$$

- When the location is clean, it alternates between moving from `A` to `B` and vice versa.
- When the location is dirty, it focuses on cleaning the location before continuing its behavior.

[[Algorithm 1 (brute force (policy))]]

[[Algorithm 2 (random search(policy))]]
